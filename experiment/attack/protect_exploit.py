import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

import os

data_dir = '/data/wangshu/wangshu_code/data'
output_dir = '/data/wangshu/wangshu_code/backdoor-pytorch/experiment/out/'
# Assuming you have a SimpleCNN model definition as before
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, 3)
        self.pool1 = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(32, 64, 3)
        self.pool2 = nn.MaxPool2d(2, 2)  # Added second pooling layer
        self.fc1 = nn.Linear(64 * 5 * 5, 1024)
        self.dropout = nn.Dropout(0.5)  # Added dropout layer
        self.fc2 = nn.Linear(1024, 10)

    def forward(self, x):
        x = self.pool1(F.relu(self.conv1(x)))
        x = self.pool2(F.relu(self.conv2(x)))  # Added second pooling layer
        x = x.view(-1, 64 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = self.dropout(x)  # Added dropout layer
        x = self.fc2(x)
        return x

# Load the pre-trained model
model = SimpleCNN()
model.load_state_dict(torch.load(os.path.join(output_dir, 'best_model.pth')))
model.eval()

# Load the MNIST dataset
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])
test_data = datasets.MNIST(root=data_dir, train=False, download=True, transform=transform)
test_loader = DataLoader(test_data, batch_size=128, shuffle=False)

# Define a perturbation function (e.g., fixed perturbation)
def fixed_perturbation(input, sigma=0.1, p=0.2):
    perturb = torch.FloatTensor(input.shape).uniform_(-sigma, sigma).to(input.device)
    mask = torch.FloatTensor(input.shape).uniform_(0, 1).to(input.device)
    mask = (mask > p).float()
    perturb *= mask
    return input + perturb

# Evaluate the model on clean and perturbed samples
# for data, target in test_loader:
#     output_clean = model(data)
#     output_perturbed = model(fixed_perturbation(data))

#     # Compute softmax probabilities for clean and perturbed samples
#     probs_clean = F.softmax(output_clean, dim=1)
#     probs_perturbed = F.softmax(output_perturbed, dim=1)

#     # Get the top and bottom 3 probabilities and their indices for clean samples
#     top3_probs_clean, top3_indices_clean = torch.topk(probs_clean, 3, dim=1)
#     bottom3_probs_clean, bottom3_indices_clean = torch.topk(-probs_clean, 3, dim=1)
#     bottom3_probs_clean = -bottom3_probs_clean

#     # Get the top and bottom 3 probabilities and their indices for perturbed samples
#     top3_probs_perturbed, top3_indices_perturbed = torch.topk(probs_perturbed, 3, dim=1)
#     bottom3_probs_perturbed, bottom3_indices_perturbed = torch.topk(-probs_perturbed, 3, dim=1)
#     bottom3_probs_perturbed = -bottom3_probs_perturbed

#     # Print the results
#     for i in range(data.size(0)):
#         print(f"Sample {i}:")
#         print(f"True Label: {target[i]}, Confidence (clean): {probs_clean[i][target[i]]:.4f}, Confidence (perturbed): {probs_perturbed[i][target[i]]:.4f}")
#         print(f"Top 3 (clean): {top3_indices_clean[i]} with probabilities {top3_probs_clean[i]}")
#         print(f"Bottom 3 (clean): {bottom3_indices_clean[i]} with probabilities {bottom3_probs_clean[i]}")
#         print(f"Top 3 (perturbed): {top3_indices_perturbed[i]} with probabilities {top3_probs_perturbed[i]}")
#         print(f"Bottom 3 (perturbed): {bottom3_indices_perturbed[i]} with probabilities {bottom3_probs_perturbed[i]}")
#         print("------")


# correct_second_highest = 0
# correct_third_highest = 0
# total_samples = 0

# Evaluate the model on clean samples
# for data, target in test_loader:
#     output_clean = model(data)
#     probs_clean = F.softmax(output_clean, dim=1)
    
#     # Get the top 3 logits and their indices for clean samples
#     _, top3_indices_clean = torch.topk(probs_clean, 3, dim=1)
    
#     # Check if the second or third highest logits match the true label
#     correct_second_highest += (top3_indices_clean[:, 1] == target).sum().item()
#     correct_third_highest += (top3_indices_clean[:, 2] == target).sum().item()
    
#     total_samples += target.size(0)

# # Calculate precision
# precision_second_highest = correct_second_highest / total_samples
# precision_third_highest = correct_third_highest / total_samples

# print(f"Precision using second highest logit: {precision_second_highest:.4f}")
# print(f"Precision using third highest logit: {precision_third_highest:.4f}")


# correct_top3 = 0
# total_samples = 0
# for data, target in test_loader:
#     output_clean = model(data)
    
#     # Get the top 3 logits and their indices for clean samples
#     _, top3_indices_clean = torch.topk(output_clean, 3, dim=1)
    
#     # Check if the true label is among the top 3 logits
#     for i in range(data.size(0)):
#         if target[i] in top3_indices_clean[i]:
#             correct_top3 += 1
    
#     total_samples += target.size(0)

# # Calculate top-3 accuracy
# top3_accuracy = correct_top3 / total_samples

# print(f"Top-3 Accuracy: {top3_accuracy:.4f}")



correct_clean = 0
correct_perturbed = 0
total_samples = 0

# Evaluate the model on both clean and perturbed samples
for data, target in test_loader:
    # Clean samples
    output_clean = model(data)
    _, predicted_clean = torch.max(output_clean.data, 1)
    correct_clean += (predicted_clean == target).sum().item()

    # Perturbed samples
    data_perturbed = fixed_perturbation(data)
    output_perturbed = model(data_perturbed)
    _, predicted_perturbed = torch.max(output_perturbed.data, 1)
    correct_perturbed += (predicted_perturbed == target).sum().item()

    total_samples += target.size(0)

# Calculate clean and perturbed accuracy
clean_accuracy = correct_clean / total_samples
perturbed_accuracy = correct_perturbed / total_samples

print(f"Clean Accuracy: {clean_accuracy:.4f}")
print(f"Perturbed Accuracy: {perturbed_accuracy:.4f}")